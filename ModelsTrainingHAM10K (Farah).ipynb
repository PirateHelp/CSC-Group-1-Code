{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RXIPZMI5TkiL"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models, losses, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential,Model,load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling1D,Input,concatenate, Activation, Dropout, Lambda,Concatenate, Reshape, Dot,MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Subtract\n",
    "from tensorflow.keras.layers import Input, Dot, Multiply\n",
    "from tensorflow.keras.optimizers import Adam , SGD\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jiP3o_X3Tn0f"
   },
   "outputs": [],
   "source": [
    "augmented_metadata_path = \"augmented_metadata.csv\"\n",
    "augmented_images_dir = \"augmented_dataset_ham10k\"\n",
    "augmented_metadata = pd.read_csv(augmented_metadata_path)\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
      "\n",
      "                                image_path  \n",
      "0  HAM10000_images_part_1\\ISIC_0027419.jpg  \n",
      "1  HAM10000_images_part_1\\ISIC_0025030.jpg  \n",
      "2  HAM10000_images_part_1\\ISIC_0026769.jpg  \n",
      "3  HAM10000_images_part_1\\ISIC_0025661.jpg  \n",
      "4  HAM10000_images_part_2\\ISIC_0031633.jpg  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'augmented_metadata_path' is the path to your CSV file\n",
    "augmented_metadata_path = 'augmented_metadata.csv'  # Replace with your actual file path\n",
    "\n",
    "# Load the CSV into a Pandas DataFrame\n",
    "metadata = pd.read_csv(augmented_metadata_path)\n",
    "\n",
    "# Now you can inspect the DataFrame\n",
    "print(metadata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0027419.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0025030.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0026769.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>HAM10000_images_part_1\\ISIC_0025661.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>HAM10000_images_part_2\\ISIC_0031633.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                image_path  \n",
       "0  HAM10000_images_part_1\\ISIC_0027419.jpg  \n",
       "1  HAM10000_images_part_1\\ISIC_0025030.jpg  \n",
       "2  HAM10000_images_part_1\\ISIC_0026769.jpg  \n",
       "3  HAM10000_images_part_1\\ISIC_0025661.jpg  \n",
       "4  HAM10000_images_part_2\\ISIC_0031633.jpg  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rx-J3JfYTuqr"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    # Load and resize image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = image.resize((128, 128))\n",
    "\n",
    "    # Convert to grayscale by averaging RGB channels\n",
    "    image_np = np.array(image)\n",
    "    gray_image = np.mean(image_np, axis=2, keepdims=True)  # Shape: (224, 224, 1)\n",
    "\n",
    "    # Normalize to [0, 1] range\n",
    "    gray_image = gray_image / 255.0\n",
    "    return gray_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rj3n21ncTy-l"
   },
   "outputs": [],
   "source": [
    "class HAM10000Dataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, metadata, batch_size=32, is_train=True):\n",
    "        self.metadata = metadata\n",
    "        self.batch_size = batch_size\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Select batch of data\n",
    "        batch_metadata = self.metadata.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        images, labels = [], []\n",
    "\n",
    "        for _, row in batch_metadata.iterrows():\n",
    "            image_path = f'augmented_dataset_ham10k/{row[\"image_id\"]}.jpg'\n",
    "            label = row['dx']\n",
    "\n",
    "            # Skip if the image file does not exist\n",
    "            if not os.path.exists(image_path):\n",
    "                #print(f\"Image not found: {image_path}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Process image to grayscale\n",
    "            gray_image = preprocess_image(image_path)\n",
    "            images.append(gray_image)\n",
    "            labels.append(class_to_idx[label])\n",
    "\n",
    "        assert len(images) == len(labels), \"Mismatch between images and labels!\"\n",
    "\n",
    "        # Convert lists to numpy arrays\n",
    "        images = np.array(images, dtype=\"float32\")\n",
    "        #labels = np.array(labels, dtype=\"int32\")\n",
    "        labels = tf.keras.utils.to_categorical(labels, num_classes=len(classes))\n",
    "\n",
    "        #print(f\"Batch shape: {np.array(images).shape}, Labels shape: {np.array(labels).shape}\")\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (16588, 128, 128, 1), Train labels shape: (16588, 7)\n",
      "Test images shape: (4117, 128, 128, 1), Test labels shape: (4117, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming `metadata` is a Pandas DataFrame containing 'image_id' and 'dx' columns.\n",
    "# You can load your metadata like this:\n",
    "# metadata = pd.read_csv('path_to_metadata.csv')\n",
    "\n",
    "# Split the metadata into train and test sets\n",
    "train_metadata, test_metadata = train_test_split(metadata, test_size=0.2, random_state=42, stratify=metadata['dx'])\n",
    "\n",
    "# Define constants\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create dataset objects for train and test\n",
    "train_dataset = HAM10000Dataset(train_metadata, batch_size=BATCH_SIZE, is_train=True)\n",
    "test_dataset = HAM10000Dataset(test_metadata, batch_size=BATCH_SIZE, is_train=False)\n",
    "\n",
    "# Helper function to load all data from a dataset\n",
    "def load_data(dataset):\n",
    "    images, labels = [], []\n",
    "    for i in range(len(dataset)):\n",
    "        batch_images, batch_labels = dataset[i]\n",
    "        images.append(batch_images)\n",
    "        labels.append(batch_labels)\n",
    "    return np.concatenate(images), np.concatenate(labels)\n",
    "\n",
    "# Load train and test data\n",
    "train_images, train_labels = load_data(train_dataset)\n",
    "test_images, test_labels = load_data(test_dataset)\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"Train images shape: {train_images.shape}, Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Test images shape: {test_images.shape}, Test labels shape: {test_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0u7LuwuDT3gW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of images shape: (13, 128, 128, 1)\n",
      "Batch of labels: (13, 7)\n"
     ]
    }
   ],
   "source": [
    "classes = augmented_metadata['dx'].unique()\n",
    "class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
    "# Split the dataset\n",
    "train_metadata, test_metadata = train_test_split(augmented_metadata, test_size=0.2, stratify=augmented_metadata['dx'])\n",
    "\n",
    "# Initialize train and test datasets\n",
    "train_dataset = HAM10000Dataset(train_metadata, batch_size=20)[0]\n",
    "test_dataset = HAM10000Dataset(test_metadata, batch_size=20)[0]\n",
    "#train_dataset = train_dataset.batch(32, drop_remainder=True)\n",
    "train_label = HAM10000Dataset(train_metadata, batch_size=20)\n",
    "test_label = HAM10000Dataset(test_metadata, batch_size=20)\n",
    "# Verify shapes of a batch\n",
    "train_images, train_labels = train_dataset[0]\n",
    "print(\"Batch of images shape:\", train_images.shape)  # Should be (32, 224, 224, 1)\n",
    "print(\"Batch of labels:\", train_labels.shape)\n",
    "\n",
    "def generate_gaussian_kernel(sigma, kernel_size):\n",
    "    \"\"\"Generate a 2D Gaussian kernel array.\"\"\"\n",
    "    # Ensure that the axis values are floats to avoid type issues during operations\n",
    "    ax = tf.range(-kernel_size // 2 + 1, kernel_size // 2 + 1, dtype=tf.float32)\n",
    "    xx, yy = tf.meshgrid(ax, ax)\n",
    "    kernel = tf.exp(-(xx**2 + yy**2) / (2. * sigma**2))\n",
    "    kernel = kernel / tf.reduce_sum(kernel)\n",
    "    return kernel.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function to extract SIFT features with consistent dimensions\n",
    "def extract_sift_features(images, max_features=500):\n",
    "    sift_features = []\n",
    "    for img in images:\n",
    "        keypoints, descriptors = sift.detectAndCompute((img * 255).astype('uint8'), None)\n",
    "        if descriptors is None:  # Handle cases where no keypoints are detected\n",
    "            descriptors = np.zeros((1, 128))\n",
    "        # Flatten descriptors and pad/truncate to max_features length\n",
    "        flat_descriptors = descriptors.flatten()\n",
    "        if len(flat_descriptors) < max_features:\n",
    "            flat_descriptors = np.pad(flat_descriptors, (0, max_features - len(flat_descriptors)))\n",
    "        else:\n",
    "            flat_descriptors = flat_descriptors[:max_features]\n",
    "        sift_features.append(flat_descriptors)\n",
    "    return np.array(sift_features, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function to extract SIFT features with consistent dimensions\n",
    "def extract_sift_features(images, max_features=500):\n",
    "    sift_features = []\n",
    "    for img in images:\n",
    "        keypoints, descriptors = sift.detectAndCompute((img * 255).astype('uint8'), None)\n",
    "        if descriptors is None:  # Handle cases where no keypoints are detected\n",
    "            descriptors = np.zeros((1, 128))\n",
    "        # Flatten descriptors and pad/truncate to max_features length\n",
    "        flat_descriptors = descriptors.flatten()\n",
    "        if len(flat_descriptors) < max_features:\n",
    "            flat_descriptors = np.pad(flat_descriptors, (0, max_features - len(flat_descriptors)))\n",
    "        else:\n",
    "            flat_descriptors = flat_descriptors[:max_features]\n",
    "        sift_features.append(flat_descriptors)\n",
    "    return np.array(sift_features, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SIFT feature extractor\n",
    "import cv2\n",
    "sift = cv2.SIFT_create(nfeatures=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT features extracted for training and test sets.\n"
     ]
    }
   ],
   "source": [
    "X_train_sift = extract_sift_features(train_images)\n",
    "X_test_sift = extract_sift_features(test_images)\n",
    "print(f\"SIFT features extracted for training and test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46417294146222976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Convert one-hot encoded labels to class indices\n",
    "train_labels_1d = np.argmax(train_labels, axis=1)\n",
    "test_labels_1d = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Train SVM on SIFT features\n",
    "svm = SVC(kernel='rbf', C=1)  # Radial Basis Function kernel\n",
    "svm.fit(X_train_sift, train_labels_1d)\n",
    "\n",
    "# Evaluate SVM on test data\n",
    "y_pred_svm = svm.predict(X_test_sift)\n",
    "\n",
    "# Optionally, calculate accuracy or other metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(test_labels_1d, y_pred_svm)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy on SIFT features: 0.5239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train KNN on SIFT features\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # Using 5 nearest neighbors\n",
    "knn.fit(X_train_sift, train_labels_1d)\n",
    "\n",
    "# Evaluate KNN on test data\n",
    "y_pred_knn = knn.predict(X_test_sift)\n",
    "knn_accuracy = accuracy_score(test_labels_1d, y_pred_knn)\n",
    "\n",
    "print(f\"KNN Accuracy on SIFT features: {knn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy on SIFT features: 0.7420\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest on SIFT features\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)  # 100 trees\n",
    "random_forest.fit(X_train_sift, train_labels_1d)\n",
    "\n",
    "# Evaluate Random Forest on test data\n",
    "y_pred_rf = random_forest.predict(X_test_sift)\n",
    "rf_accuracy = accuracy_score(test_labels_1d, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest Accuracy on SIFT features: {rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy on SIFT features: 0.6954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train Decision Tree on SIFT features\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)  # Set a random state for reproducibility\n",
    "decision_tree.fit(X_train_sift, train_labels_1d)\n",
    "\n",
    "# Evaluate Decision Tree on test data\n",
    "y_pred_dt = decision_tree.predict(X_test_sift)\n",
    "dt_accuracy = accuracy_score(test_labels_1d, y_pred_dt)\n",
    "\n",
    "print(f\"Decision Tree Accuracy on SIFT features: {dt_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT features extracted for training and test sets with 400 keypoints.\n"
     ]
    }
   ],
   "source": [
    "# Re-initialize SIFT feature extractor with 400 keypoints\n",
    "sift = cv2.SIFT_create(nfeatures=400)\n",
    "\n",
    "# Re-extract SIFT features for training and test sets\n",
    "X_train_sift = extract_sift_features(train_images)\n",
    "X_test_sift = extract_sift_features(test_images)\n",
    "\n",
    "print(f\"SIFT features extracted for training and test sets with 400 keypoints.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on SIFT features (400 keypoints): 0.4622\n",
      "k-NN Accuracy on SIFT features (400 keypoints): 0.5230\n",
      "Decision Tree Accuracy on SIFT features (400 keypoints): 0.7051\n",
      "Random Forest Accuracy on SIFT features (400 keypoints): 0.7459\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Retrain and evaluate SVM\n",
    "svm = SVC(kernel='rbf', C=1)\n",
    "svm.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_svm = svm.predict(X_test_sift)\n",
    "svm_accuracy = accuracy_score(test_labels_1d, y_pred_svm)\n",
    "print(f\"SVM Accuracy on SIFT features (400 keypoints): {svm_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_knn = knn.predict(X_test_sift)\n",
    "knn_accuracy = accuracy_score(test_labels_1d, y_pred_knn)\n",
    "print(f\"k-NN Accuracy on SIFT features (400 keypoints): {knn_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_dt = decision_tree.predict(X_test_sift)\n",
    "dt_accuracy = accuracy_score(test_labels_1d, y_pred_dt)\n",
    "print(f\"Decision Tree Accuracy on SIFT features (400 keypoints): {dt_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_rf = random_forest.predict(X_test_sift)\n",
    "rf_accuracy = accuracy_score(test_labels_1d, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy on SIFT features (400 keypoints): {rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT features extracted for training and test sets with 100 keypoints.\n"
     ]
    }
   ],
   "source": [
    "sift = cv2.SIFT_create(nfeatures=100)\n",
    "\n",
    "# Re-extract SIFT features for training and test sets\n",
    "X_train_sift = extract_sift_features(train_images)\n",
    "X_test_sift = extract_sift_features(test_images)\n",
    "\n",
    "print(f\"SIFT features extracted for training and test sets with 100 keypoints.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on SIFT features (100 keypoints): 0.4586\n",
      "k-NN Accuracy on SIFT features (100 keypoints): 0.5251\n",
      "Decision Tree Accuracy on SIFT features (100 keypoints): 0.7059\n",
      "Random Forest Accuracy on SIFT features (100 keypoints): 0.7367\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Retrain and evaluate SVM\n",
    "svm = SVC(kernel='rbf', C=1)\n",
    "svm.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_svm = svm.predict(X_test_sift)\n",
    "svm_accuracy = accuracy_score(test_labels_1d, y_pred_svm)\n",
    "print(f\"SVM Accuracy on SIFT features (100 keypoints): {svm_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_knn = knn.predict(X_test_sift)\n",
    "knn_accuracy = accuracy_score(test_labels_1d, y_pred_knn)\n",
    "print(f\"k-NN Accuracy on SIFT features (100 keypoints): {knn_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_dt = decision_tree.predict(X_test_sift)\n",
    "dt_accuracy = accuracy_score(test_labels_1d, y_pred_dt)\n",
    "print(f\"Decision Tree Accuracy on SIFT features (100 keypoints): {dt_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_rf = random_forest.predict(X_test_sift)\n",
    "rf_accuracy = accuracy_score(test_labels_1d, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy on SIFT features (100 keypoints): {rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT features extracted for training and test sets with 200 keypoints.\n"
     ]
    }
   ],
   "source": [
    "sift = cv2.SIFT_create(nfeatures=200)\n",
    "\n",
    "# Re-extract SIFT features for training and test sets\n",
    "X_train_sift = extract_sift_features(train_images)\n",
    "X_test_sift = extract_sift_features(test_images)\n",
    "\n",
    "print(f\"SIFT features extracted for training and test sets with 200 keypoints.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on SIFT features (200 keypoints): 0.4622\n",
      "k-NN Accuracy on SIFT features (200 keypoints): 0.5227\n",
      "Decision Tree Accuracy on SIFT features (200 keypoints): 0.7049\n",
      "Random Forest Accuracy on SIFT features (200 keypoints): 0.7462\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Retrain and evaluate SVM\n",
    "svm = SVC(kernel='rbf', C=1)\n",
    "svm.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_svm = svm.predict(X_test_sift)\n",
    "svm_accuracy = accuracy_score(test_labels_1d, y_pred_svm)\n",
    "print(f\"SVM Accuracy on SIFT features (200 keypoints): {svm_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_knn = knn.predict(X_test_sift)\n",
    "knn_accuracy = accuracy_score(test_labels_1d, y_pred_knn)\n",
    "print(f\"k-NN Accuracy on SIFT features (200 keypoints): {knn_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_dt = decision_tree.predict(X_test_sift)\n",
    "dt_accuracy = accuracy_score(test_labels_1d, y_pred_dt)\n",
    "print(f\"Decision Tree Accuracy on SIFT features (200 keypoints): {dt_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_rf = random_forest.predict(X_test_sift)\n",
    "rf_accuracy = accuracy_score(test_labels_1d, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy on SIFT features (200 keypoints): {rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT features extracted for training and test sets with 500 keypoints.\n"
     ]
    }
   ],
   "source": [
    "sift = cv2.SIFT_create(nfeatures=500)\n",
    "\n",
    "# Re-extract SIFT features for training and test sets\n",
    "X_train_sift = extract_sift_features(train_images)\n",
    "X_test_sift = extract_sift_features(test_images)\n",
    "\n",
    "print(f\"SIFT features extracted for training and test sets with 500 keypoints.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on SIFT features (500 keypoints): 0.4622\n",
      "k-NN Accuracy on SIFT features (500 keypoints): 0.5230\n",
      "Decision Tree Accuracy on SIFT features (500 keypoints): 0.7051\n",
      "Random Forest Accuracy on SIFT features (500 keypoints): 0.7459\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Retrain and evaluate SVM\n",
    "svm = SVC(kernel='rbf', C=1)\n",
    "svm.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_svm = svm.predict(X_test_sift)\n",
    "svm_accuracy = accuracy_score(test_labels_1d, y_pred_svm)\n",
    "print(f\"SVM Accuracy on SIFT features (500 keypoints): {svm_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_knn = knn.predict(X_test_sift)\n",
    "knn_accuracy = accuracy_score(test_labels_1d, y_pred_knn)\n",
    "print(f\"k-NN Accuracy on SIFT features (500 keypoints): {knn_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_dt = decision_tree.predict(X_test_sift)\n",
    "dt_accuracy = accuracy_score(test_labels_1d, y_pred_dt)\n",
    "print(f\"Decision Tree Accuracy on SIFT features (500 keypoints): {dt_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_rf = random_forest.predict(X_test_sift)\n",
    "rf_accuracy = accuracy_score(test_labels_1d, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy on SIFT features (500 keypoints): {rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saadaoui\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_18               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_19               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_20               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">786,688</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_18               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m24,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_19               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m98,560\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_20               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m786,688\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">914,570</span> (3.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m914,570\u001b[0m (3.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">913,674</span> (3.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m913,674\u001b[0m (3.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "\n",
    "# Define the CNN model for SIFT features\n",
    "def create_cnn_for_sift(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        # Convolutional Layer 1\n",
    "        Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "\n",
    "        # Convolutional Layer 2\n",
    "        Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "\n",
    "        # Convolutional Layer 3\n",
    "        Conv1D(256, kernel_size=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "\n",
    "        # Flatten and Fully Connected Layers\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  # Output layer for classification\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "# Assuming SIFT features have 128 dimensions per feature vector\n",
    "input_shape = (100, 1)  # For SIFT features (e.g., 128 descriptors)\n",
    "num_classes = 10  # Number of classes (adjust as needed for your dataset)\n",
    "\n",
    "# Create the model\n",
    "model = create_cnn_for_sift(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse_categorical_crossentropy if labels are integers\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_8\" is incompatible with the layer: expected axis -1 of input shape to have value 3072, but received input with shape (None, 15872)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 500), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_sift, train_labels_1d, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_8\" is incompatible with the layer: expected axis -1 of input shape to have value 3072, but received input with shape (None, 15872)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 500), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_sift, train_labels_1d, epochs=20, batch_size=64, validation_split=0.2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5868 - loss: 1.0226\n",
      "Test accuracy: 0.5941219329833984\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_sift, test_labels_1d)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT features extracted for training and test sets with 25 keypoints.\n"
     ]
    }
   ],
   "source": [
    "sift = cv2.SIFT_create(nfeatures=25)\n",
    "\n",
    "# Re-extract SIFT features for training and test sets\n",
    "X_train_sift = extract_sift_features(train_images)\n",
    "X_test_sift = extract_sift_features(test_images)\n",
    "\n",
    "print(f\"SIFT features extracted for training and test sets with 25 keypoints.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on SIFT features (25 keypoints): 0.4800\n",
      "k-NN Accuracy on SIFT features (25 keypoints): 0.5424\n",
      "Decision Tree Accuracy on SIFT features (25 keypoints): 0.7088\n",
      "Random Forest Accuracy on SIFT features (25 keypoints): 0.7542\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Retrain and evaluate SVM\n",
    "svm = SVC(kernel='rbf', C=1)\n",
    "svm.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_svm = svm.predict(X_test_sift)\n",
    "svm_accuracy = accuracy_score(test_labels_1d, y_pred_svm)\n",
    "print(f\"SVM Accuracy on SIFT features (25 keypoints): {svm_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_knn = knn.predict(X_test_sift)\n",
    "knn_accuracy = accuracy_score(test_labels_1d, y_pred_knn)\n",
    "print(f\"k-NN Accuracy on SIFT features (25 keypoints): {knn_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_dt = decision_tree.predict(X_test_sift)\n",
    "dt_accuracy = accuracy_score(test_labels_1d, y_pred_dt)\n",
    "print(f\"Decision Tree Accuracy on SIFT features (25 keypoints): {dt_accuracy:.4f}\")\n",
    "\n",
    "# Retrain and evaluate Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train_sift, train_labels_1d)\n",
    "y_pred_rf = random_forest.predict(X_test_sift)\n",
    "rf_accuracy = accuracy_score(test_labels_1d, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy on SIFT features (25 keypoints): {rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "67guBETaUAh4"
   },
   "outputs": [],
   "source": [
    "def create_fixed_gaussian_layer(sigma, kernel_size, input_channels, stride):\n",
    "    \"\"\"Create a fixed Gaussian Conv2D layer.\"\"\"\n",
    "    kernel = generate_gaussian_kernel(sigma, kernel_size)\n",
    "    kernel = np.expand_dims(kernel, axis=-1)  # Shape: (kernel_size, kernel_size, 1)\n",
    "    kernel = np.repeat(kernel, input_channels, axis=-1)  # Shape: (kernel_size, kernel_size, input_channels)\n",
    "    kernel = np.expand_dims(kernel, axis=-1)  # Shape: (kernel_size, kernel_size, input_channels, 1)\n",
    "\n",
    "    # Use Conv2D for applying Gaussian kernel with stride\n",
    "    gauss_layer = layers.Conv2D(filters=input_channels, kernel_size=(kernel_size, kernel_size),\n",
    "                                strides=(stride, stride), padding=\"same\", use_bias=False)\n",
    "    gauss_layer.build((None, None, None, input_channels))  # Adjust input shape in build method\n",
    "    gauss_layer.set_weights([kernel])  # Set Gaussian kernel as weights\n",
    "    gauss_layer.trainable = False  # Freeze weights\n",
    "    return gauss_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "W_dMCAijUD-K"
   },
   "outputs": [],
   "source": [
    "class KeypointDetectionLayer(layers.Layer):\n",
    "    def __init__(self, contrast_threshold=0.0001, edge_threshold=1, **kwargs):\n",
    "        super(KeypointDetectionLayer, self).__init__(**kwargs)\n",
    "        self.contrast_threshold = contrast_threshold\n",
    "        self.edge_threshold = edge_threshold\n",
    "\n",
    "    def call(self, inputs):\n",
    "        DoG_s, DoG_s1, DoG_s2 = inputs\n",
    "        DoG_s = tf.clip_by_value(DoG_s, 0.0, 1.0)\n",
    "        DoG_s1=tf.clip_by_value(DoG_s1, 0.0, 1.0)\n",
    "        DoG_s2=tf.clip_by_value(DoG_s2, 0.0, 1.0)\n",
    "\n",
    "        patches_s = tf.image.extract_patches(images=DoG_s, sizes=[1, 3, 3, 1], strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding='SAME')\n",
    "        patches_s1 = tf.image.extract_patches(images=DoG_s1, sizes=[1, 3, 3, 1], strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding='SAME')\n",
    "        patches_s2 = tf.image.extract_patches(images=DoG_s2, sizes=[1, 3, 3, 1], strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        combined_patches = tf.concat([patches_s, patches_s1, patches_s2], axis=-1)\n",
    "\n",
    "        center_pixel_s1 = patches_s1[..., 4]\n",
    "        max_in_neighborhood = tf.reduce_max(combined_patches, axis=-1)\n",
    "        min_in_neighborhood = tf.reduce_min(combined_patches, axis=-1)\n",
    "        is_max = tf.equal(center_pixel_s1, max_in_neighborhood)\n",
    "        is_min = tf.equal(center_pixel_s1, min_in_neighborhood)\n",
    "        keypoints = tf.logical_or(is_max, is_min)\n",
    "        high_contrast = tf.abs(center_pixel_s1) > self.contrast_threshold\n",
    "        keypoints = tf.cast(tf.logical_and(keypoints, high_contrast), dtype=tf.float32)\n",
    "\n",
    "        # Edge response elimination\n",
    "        dx = 0.5 * (patches_s1[..., 5] - patches_s1[..., 3])\n",
    "        dy = 0.5 * (patches_s1[..., 7] - patches_s1[..., 1])\n",
    "        dxx = patches_s1[..., 5] + patches_s1[..., 3] - 2 * center_pixel_s1\n",
    "        dyy = patches_s1[..., 7] + patches_s1[..., 1] - 2 * center_pixel_s1\n",
    "        dxy = 0.25 * (patches_s1[..., 8] + patches_s1[..., 0] - patches_s1[..., 2] - patches_s1[..., 6])\n",
    "\n",
    "        trH = dxx + dyy\n",
    "        detH = dxx * dyy - dxy * dxy\n",
    "        edge_response = (trH * trH) / (detH + 1e-10)  # Add small epsilon to avoid division by zero\n",
    "        is_not_edge = edge_response < ((self.edge_threshold + 1) ** 2) / self.edge_threshold\n",
    "        is_not_edge = tf.cast(is_not_edge, dtype=tf.bool)\n",
    "        keypoints = tf.cast(tf.logical_and(tf.cast(keypoints, dtype=tf.bool), is_not_edge), dtype=tf.float32)\n",
    "\n",
    "        return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6zNBST9OUMWq"
   },
   "outputs": [],
   "source": [
    "def build_model_with_individual_outputs(input_shape,channels,learning_rate,batch_size, dropout_rate,first_dense_nodes,second_dense_nodes,l2_reg):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    outputs = []\n",
    "    stride=1\n",
    "    dog_outputs = []\n",
    "    #### octave 1 ###\n",
    "    ##### Conv layers 1 ###\n",
    "    gauss_layer1 = create_fixed_gaussian_layer(1.6, 7, channels, stride=1)\n",
    "    x1 = gauss_layer1(x)\n",
    "    outputs.append(x)\n",
    "    outputs.append(x1)\n",
    "    gauss_layer2 = create_fixed_gaussian_layer(2.26, 15, channels, stride= 1)\n",
    "    x2 = gauss_layer2(x)\n",
    "    outputs.append(x2)\n",
    "    gauss_layer3 = create_fixed_gaussian_layer(3.2,20,channels, stride=1)\n",
    "    x3 = gauss_layer3(x)\n",
    "    outputs.append(x3)\n",
    "    gauss_layer4 = create_fixed_gaussian_layer(4.52, 28, channels, stride= 1)\n",
    "    x4 = gauss_layer4(x)\n",
    "    outputs.append(x4)\n",
    "    #### DOG layers 1 #####\n",
    "    dog_layer1_1 = layers.Subtract(name=f'dog_{1}_{1}')([x1,x2])\n",
    "    #dog_layer1_11= blackwhite()(dog_layer1_1)\n",
    "    outputs.append(dog_layer1_1)\n",
    "    dog_layer2_1=layers.Subtract(name=f'dog_{1}_{2}')([x2,x3])\n",
    "    outputs.append(dog_layer2_1)\n",
    "    #dog_layer2_11= blackwhite()(dog_layer2_1)\n",
    "    #outputs.append(dog_layer2_11)\n",
    "    dog_layer3_1=layers.Subtract(name=f'dog_{1}_{3}')([x3,x4])\n",
    "    outputs.append(dog_layer3_1)\n",
    "    #dog_layer3_11= blackwhite()(dog_layer3_1)\n",
    "    # outputs.append(dog_layer3_11)\n",
    "    #### keypoint detection layers 1#####\n",
    "    kp_layer1_1 = KeypointDetectionLayer()([dog_layer1_1, dog_layer2_1,dog_layer3_1])\n",
    "    outputs.append(kp_layer1_1)\n",
    "\n",
    "    ###### octave2 ######\n",
    "    ##### Conv layers 2 ###\n",
    "    Maxpool1 = MaxPooling2D((2, 2))(x3)\n",
    "    outputs.append(Maxpool1)\n",
    "    Maxpool2 = MaxPooling2D((2, 2))(x4)\n",
    "    outputs.append(Maxpool2)\n",
    "    gauss_layer3_2 = create_fixed_gaussian_layer(6.4, 39, channels, stride=2)\n",
    "    x3_2 = gauss_layer3_2(x)\n",
    "    outputs.append(x3_2)\n",
    "    gauss_layer4_2 = create_fixed_gaussian_layer(9.05, 55, channels, stride=2)\n",
    "    x4_2 = gauss_layer4_2(x)\n",
    "    outputs.append(x4_2)\n",
    "    #### DOG layers 2#####\n",
    "    dog_layer1_2 = layers.Subtract(name=f'dog_{2}_{1}')([Maxpool1,Maxpool2])\n",
    "    #dog_layer1_22= blackwhite()(dog_layer1_2)\n",
    "    outputs.append(dog_layer1_2)\n",
    "    dog_layer2_2=layers.Subtract(name=f'dog_{2}_{2}')([Maxpool2,x3_2])\n",
    "    #dog_layer2_22= blackwhite()(dog_layer2_2)\n",
    "    outputs.append(dog_layer2_2)\n",
    "    dog_layer3_2=layers.Subtract(name=f'dog_{2}_{3}')([x3_2,x4_2])\n",
    "    #dog_layer3_22= blackwhite()(dog_layer3_2)\n",
    "    outputs.append(dog_layer3_2)\n",
    "\n",
    "    #### keypoint detection layers 2#####\n",
    "    kp_layer1_2 = KeypointDetectionLayer()([dog_layer1_2, dog_layer2_2,dog_layer3_2])\n",
    "    outputs.append(kp_layer1_2)\n",
    "     ###### octave3 ######\n",
    "    ##### Conv layers 3 ###\n",
    "    Maxpool1_3 = MaxPooling2D((2, 2))(x3_2)\n",
    "    outputs.append(Maxpool1)\n",
    "    Maxpool2_3 = MaxPooling2D((2, 2))(x4_2)\n",
    "    outputs.append(Maxpool2)\n",
    "    gauss_layer3_3 = create_fixed_gaussian_layer(12.8, 77, channels, stride=4)\n",
    "    x3_3 = gauss_layer3_3(x)\n",
    "    outputs.append(x3_3)\n",
    "    gauss_layer4_3= create_fixed_gaussian_layer(18.1, 110, channels, stride=4)\n",
    "    x4_3 = gauss_layer4_3(x)\n",
    "    outputs.append(x4_3)\n",
    "    #### DOG layers 2#####\n",
    "    dog_layer1_3 = layers.Subtract(name=f'dog_{3}_{1}')([Maxpool1_3,Maxpool2_3])\n",
    "    #dog_layer1_33= blackwhite()(dog_layer1_2)\n",
    "    outputs.append(dog_layer1_3)\n",
    "    dog_layer2_3=layers.Subtract(name=f'dog_{3}_{2}')([Maxpool2_3,x3_3])\n",
    "    #dog_layer2_33= blackwhite()(dog_layer2_2)\n",
    "    outputs.append(dog_layer2_3)\n",
    "    dog_layer3_3=layers.Subtract(name=f'dog_{3}_{3}')([x3_3,x4_3])\n",
    "    #dog_layer3_33= blackwhite()(dog_layer3_3)\n",
    "    outputs.append(dog_layer3_3)\n",
    "    kp_layer1_3 = KeypointDetectionLayer()([dog_layer1_3, dog_layer2_3,dog_layer3_3])\n",
    "    outputs.append(kp_layer1_3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    flatten1 = Flatten()(kp_layer1_1)\n",
    "    flatten2 = Flatten()(kp_layer1_2)\n",
    "    flatten3 = Flatten()(kp_layer1_3)\n",
    "    concatenated = Concatenate()([flatten1,flatten2,flatten3])\n",
    "    dense1 = Dense(first_dense_nodes, activation='relu',kernel_regularizer=l2(l2_reg))(concatenated)\n",
    "    drp=Dropout(dropout_rate)(dense1)\n",
    "    dense2 = Dense(second_dense_nodes, activation='relu',kernel_regularizer=l2(l2_reg))(dense1)\n",
    "    drp1=Dropout(dropout_rate)(dense2)\n",
    "    dense3 = Dense(128, activation='relu',kernel_regularizer=l2(l2_reg))(dense2)\n",
    "    drp3=Dropout(dropout_rate)(dense3)\n",
    "\n",
    "    output = Dense(7, activation='softmax')(dense3)\n",
    "\n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=SGD(learning_rate=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',  tf.keras.metrics.AUC(multi_label=False),\n",
    "              tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_accuracy')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "w52t6F6bXoiw",
    "outputId": "1d0fc567-3448-4a85-b713-e235e73f37bf"
   },
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 1)\n",
    "channels = 1\n",
    "model = build_model_with_individual_outputs(\n",
    "        input_shape, channels, learning_rate=0.01,\n",
    "        batch_size=128, dropout_rate=0.0, first_dense_nodes=32,\n",
    "        second_dense_nodes=256, l2_reg=1e-06\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74Y59r93ZfWU"
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\", \"fit10knew\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIjvxBziZniF"
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=50, restore_best_weights=True, verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2s7R9jcfVD0O"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8HW4tuTUwLQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m1228/1228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m994s\u001b[0m 804ms/step - accuracy: 0.1802 - auc_2: 0.6048 - loss: 1.8646 - top_5_accuracy: 0.8572 - val_accuracy: 0.2011 - val_auc_2: 0.6207 - val_loss: 1.7967 - val_top_5_accuracy: 0.8571\n",
      "Epoch 2/500\n",
      "\u001b[1m1228/1228\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m957s\u001b[0m 779ms/step - accuracy: 0.2033 - auc_2: 0.6206 - loss: 1.7927 - top_5_accuracy: 0.8635 - val_accuracy: 0.1917 - val_auc_2: 0.6228 - val_loss: 1.7865 - val_top_5_accuracy: 0.8552\n",
      "Epoch 3/500\n",
      "\u001b[1m 533/1228\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7:08\u001b[0m 616ms/step - accuracy: 0.1960 - auc_2: 0.6176 - loss: 1.7882 - top_5_accuracy: 0.8527"
     ]
    }
   ],
   "source": [
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model and save history\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=500,\n",
    "    batch_size=128,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "training_time = end_time - start_time\n",
    "print(f\"Total training time: {training_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "training_time_minutes = training_time / 60\n",
    "print(f\"Total training time: {training_time_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
